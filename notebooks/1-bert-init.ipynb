{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uncased_L-8_H-512_A-8']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../models/uncased_L-8_H-512_A-8\"\n",
    "\n",
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 4\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "# using the default token_type/segment id 0\n",
    "output = l_bert(l_input_ids)                              # output: [batch_size, max_seq_len, hidden_size]\n",
    "model = keras.Model(inputs=l_input_ids, outputs=output)\n",
    "model.build(input_shape=(None, max_seq_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 4, 512)            41109504  \n",
      "=================================================================\n",
      "Total params: 41,109,504\n",
      "Trainable params: 41,109,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [['hello' , 'how', 'are', 'you']]\n",
    "y = [[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret optimizer identifier:', <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fe7e0efe6c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run_eagerly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n\u001b[1;32m    330\u001b[0m           loss, loss_weights, output_names=self.output_names)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m       \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m       if (self._dtype_policy.loss_scale is not None and\n\u001b[1;32m    346\u001b[0m           not isinstance(opt, lso.LossScaleOptimizer)):\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not interpret optimizer identifier:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: ('Could not interpret optimizer identifier:', <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>)"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:541 train_step  **\n        self.trainable_variables)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1804 _minimize\n        trainable_variables))\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['bert/embeddings/word_embeddings/embeddings:0', 'bert/embeddings/position_embeddings/embeddings:0', 'bert/embeddings/LayerNorm/gamma:0', 'bert/embeddings/LayerNorm/beta:0', 'bert/encoder/layer_0/attention/self/query/kernel:0', 'bert/encoder/layer_0/attention/self/query/bias:0', 'bert/encoder/layer_0/attention/self/key/kernel:0', 'bert/encoder/layer_0/attention/self/key/bias:0', 'bert/encoder/layer_0/attention/self/value/kernel:0', 'bert/encoder/layer_0/attention/self/value/bias:0', 'bert/encoder/layer_0/attention/output/dense/kernel:0', 'bert/encoder/layer_0/attention/output/dense/bias:0', 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_0/intermediate/kernel:0', 'bert/encoder/layer_0/intermediate/bias:0', 'bert/encoder/layer_0/output/dense/kernel:0', 'bert/encoder/layer_0/output/dense/bias:0', 'bert/encoder/layer_0/output/LayerNorm/gamma:0', 'bert/encoder/layer_0/output/LayerNorm/beta:0', 'bert/encoder/layer_1/attention/self/query/kernel:0', 'bert/encoder/layer_1/attention/self/query/bias:0', 'bert/encoder/layer_1/attention/self/key/kernel:0', 'bert/encoder/layer_1/attention/self/key/bias:0', 'bert/encoder/layer_1/attention/self/value/kernel:0', 'bert/encoder/layer_1/attention/self/value/bias:0', 'bert/encoder/layer_1/attention/output/dense/kernel:0', 'bert/encoder/layer_1/attention/output/dense/bias:0', 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_1/intermediate/kernel:0', 'bert/encoder/layer_1/intermediate/bias:0', 'bert/encoder/layer_1/output/dense/kernel:0', 'bert/encoder/layer_1/output/dense/bias:0', 'bert/encoder/layer_1/output/LayerNorm/gamma:0', 'bert/encoder/layer_1/output/LayerNorm/beta:0', 'bert/encoder/layer_2/attention/self/query/kernel:0', 'bert/encoder/layer_2/attention/self/query/bias:0', 'bert/encoder/layer_2/attention/self/key/kernel:0', 'bert/encoder/layer_2/attention/self/key/bias:0', 'bert/encoder/layer_2/attention/self/value/kernel:0', 'bert/encoder/layer_2/attention/self/value/bias:0', 'bert/encoder/layer_2/attention/output/dense/kernel:0', 'bert/encoder/layer_2/attention/output/dense/bias:0', 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_2/intermediate/kernel:0', 'bert/encoder/layer_2/intermediate/bias:0', 'bert/encoder/layer_2/output/dense/kernel:0', 'bert/encoder/layer_2/output/dense/bias:0', 'bert/encoder/layer_2/output/LayerNorm/gamma:0', 'bert/encoder/layer_2/output/LayerNorm/beta:0', 'bert/encoder/layer_3/attention/self/query/kernel:0', 'bert/encoder/layer_3/attention/self/query/bias:0', 'bert/encoder/layer_3/attention/self/key/kernel:0', 'bert/encoder/layer_3/attention/self/key/bias:0', 'bert/encoder/layer_3/attention/self/value/kernel:0', 'bert/encoder/layer_3/attention/self/value/bias:0', 'bert/encoder/layer_3/attention/output/dense/kernel:0', 'bert/encoder/layer_3/attention/output/dense/bias:0', 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_3/intermediate/kernel:0', 'bert/encoder/layer_3/intermediate/bias:0', 'bert/encoder/layer_3/output/dense/kernel:0', 'bert/encoder/layer_3/output/dense/bias:0', 'bert/encoder/layer_3/output/LayerNorm/gamma:0', 'bert/encoder/layer_3/output/LayerNorm/beta:0', 'bert/encoder/layer_4/attention/self/query/kernel:0', 'bert/encoder/layer_4/attention/self/query/bias:0', 'bert/encoder/layer_4/attention/self/key/kernel:0', 'bert/encoder/layer_4/attention/self/key/bias:0', 'bert/encoder/layer_4/attention/self/value/kernel:0', 'bert/encoder/layer_4/attention/self/value/bias:0', 'bert/encoder/layer_4/attention/output/dense/kernel:0', 'bert/encoder/layer_4/attention/output/dense/bias:0', 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_4/intermediate/kernel:0', 'bert/encoder/layer_4/intermediate/bias:0', 'bert/encoder/layer_4/output/dense/kernel:0', 'bert/encoder/layer_4/output/dense/bias:0', 'bert/encoder/layer_4/output/LayerNorm/gamma:0', 'bert/encoder/layer_4/output/LayerNorm/beta:0', 'bert/encoder/layer_5/attention/self/query/kernel:0', 'bert/encoder/layer_5/attention/self/query/bias:0', 'bert/encoder/layer_5/attention/self/key/kernel:0', 'bert/encoder/layer_5/attention/self/key/bias:0', 'bert/encoder/layer_5/attention/self/value/kernel:0', 'bert/encoder/layer_5/attention/self/value/bias:0', 'bert/encoder/layer_5/attention/output/dense/kernel:0', 'bert/encoder/layer_5/attention/output/dense/bias:0', 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_5/intermediate/kernel:0', 'bert/encoder/layer_5/intermediate/bias:0', 'bert/encoder/layer_5/output/dense/kernel:0', 'bert/encoder/layer_5/output/dense/bias:0', 'bert/encoder/layer_5/output/LayerNorm/gamma:0', 'bert/encoder/layer_5/output/LayerNorm/beta:0', 'bert/encoder/layer_6/attention/self/query/kernel:0', 'bert/encoder/layer_6/attention/self/query/bias:0', 'bert/encoder/layer_6/attention/self/key/kernel:0', 'bert/encoder/layer_6/attention/self/key/bias:0', 'bert/encoder/layer_6/attention/self/value/kernel:0', 'bert/encoder/layer_6/attention/self/value/bias:0', 'bert/encoder/layer_6/attention/output/dense/kernel:0', 'bert/encoder/layer_6/attention/output/dense/bias:0', 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_6/intermediate/kernel:0', 'bert/encoder/layer_6/intermediate/bias:0', 'bert/encoder/layer_6/output/dense/kernel:0', 'bert/encoder/layer_6/output/dense/bias:0', 'bert/encoder/layer_6/output/LayerNorm/gamma:0', 'bert/encoder/layer_6/output/LayerNorm/beta:0', 'bert/encoder/layer_7/attention/self/query/kernel:0', 'bert/encoder/layer_7/attention/self/query/bias:0', 'bert/encoder/layer_7/attention/self/key/kernel:0', 'bert/encoder/layer_7/attention/self/key/bias:0', 'bert/encoder/layer_7/attention/self/value/kernel:0', 'bert/encoder/layer_7/attention/self/value/bias:0', 'bert/encoder/layer_7/attention/output/dense/kernel:0', 'bert/encoder/layer_7/attention/output/dense/bias:0', 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_7/intermediate/kernel:0', 'bert/encoder/layer_7/intermediate/bias:0', 'bert/encoder/layer_7/output/dense/kernel:0', 'bert/encoder/layer_7/output/dense/bias:0', 'bert/encoder/layer_7/output/LayerNorm/gamma:0', 'bert/encoder/layer_7/output/LayerNorm/beta:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cecb4634e72d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:541 train_step  **\n        self.trainable_variables)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1804 _minimize\n        trainable_variables))\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    /home/shubham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['bert/embeddings/word_embeddings/embeddings:0', 'bert/embeddings/position_embeddings/embeddings:0', 'bert/embeddings/LayerNorm/gamma:0', 'bert/embeddings/LayerNorm/beta:0', 'bert/encoder/layer_0/attention/self/query/kernel:0', 'bert/encoder/layer_0/attention/self/query/bias:0', 'bert/encoder/layer_0/attention/self/key/kernel:0', 'bert/encoder/layer_0/attention/self/key/bias:0', 'bert/encoder/layer_0/attention/self/value/kernel:0', 'bert/encoder/layer_0/attention/self/value/bias:0', 'bert/encoder/layer_0/attention/output/dense/kernel:0', 'bert/encoder/layer_0/attention/output/dense/bias:0', 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_0/intermediate/kernel:0', 'bert/encoder/layer_0/intermediate/bias:0', 'bert/encoder/layer_0/output/dense/kernel:0', 'bert/encoder/layer_0/output/dense/bias:0', 'bert/encoder/layer_0/output/LayerNorm/gamma:0', 'bert/encoder/layer_0/output/LayerNorm/beta:0', 'bert/encoder/layer_1/attention/self/query/kernel:0', 'bert/encoder/layer_1/attention/self/query/bias:0', 'bert/encoder/layer_1/attention/self/key/kernel:0', 'bert/encoder/layer_1/attention/self/key/bias:0', 'bert/encoder/layer_1/attention/self/value/kernel:0', 'bert/encoder/layer_1/attention/self/value/bias:0', 'bert/encoder/layer_1/attention/output/dense/kernel:0', 'bert/encoder/layer_1/attention/output/dense/bias:0', 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_1/intermediate/kernel:0', 'bert/encoder/layer_1/intermediate/bias:0', 'bert/encoder/layer_1/output/dense/kernel:0', 'bert/encoder/layer_1/output/dense/bias:0', 'bert/encoder/layer_1/output/LayerNorm/gamma:0', 'bert/encoder/layer_1/output/LayerNorm/beta:0', 'bert/encoder/layer_2/attention/self/query/kernel:0', 'bert/encoder/layer_2/attention/self/query/bias:0', 'bert/encoder/layer_2/attention/self/key/kernel:0', 'bert/encoder/layer_2/attention/self/key/bias:0', 'bert/encoder/layer_2/attention/self/value/kernel:0', 'bert/encoder/layer_2/attention/self/value/bias:0', 'bert/encoder/layer_2/attention/output/dense/kernel:0', 'bert/encoder/layer_2/attention/output/dense/bias:0', 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_2/intermediate/kernel:0', 'bert/encoder/layer_2/intermediate/bias:0', 'bert/encoder/layer_2/output/dense/kernel:0', 'bert/encoder/layer_2/output/dense/bias:0', 'bert/encoder/layer_2/output/LayerNorm/gamma:0', 'bert/encoder/layer_2/output/LayerNorm/beta:0', 'bert/encoder/layer_3/attention/self/query/kernel:0', 'bert/encoder/layer_3/attention/self/query/bias:0', 'bert/encoder/layer_3/attention/self/key/kernel:0', 'bert/encoder/layer_3/attention/self/key/bias:0', 'bert/encoder/layer_3/attention/self/value/kernel:0', 'bert/encoder/layer_3/attention/self/value/bias:0', 'bert/encoder/layer_3/attention/output/dense/kernel:0', 'bert/encoder/layer_3/attention/output/dense/bias:0', 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_3/intermediate/kernel:0', 'bert/encoder/layer_3/intermediate/bias:0', 'bert/encoder/layer_3/output/dense/kernel:0', 'bert/encoder/layer_3/output/dense/bias:0', 'bert/encoder/layer_3/output/LayerNorm/gamma:0', 'bert/encoder/layer_3/output/LayerNorm/beta:0', 'bert/encoder/layer_4/attention/self/query/kernel:0', 'bert/encoder/layer_4/attention/self/query/bias:0', 'bert/encoder/layer_4/attention/self/key/kernel:0', 'bert/encoder/layer_4/attention/self/key/bias:0', 'bert/encoder/layer_4/attention/self/value/kernel:0', 'bert/encoder/layer_4/attention/self/value/bias:0', 'bert/encoder/layer_4/attention/output/dense/kernel:0', 'bert/encoder/layer_4/attention/output/dense/bias:0', 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_4/intermediate/kernel:0', 'bert/encoder/layer_4/intermediate/bias:0', 'bert/encoder/layer_4/output/dense/kernel:0', 'bert/encoder/layer_4/output/dense/bias:0', 'bert/encoder/layer_4/output/LayerNorm/gamma:0', 'bert/encoder/layer_4/output/LayerNorm/beta:0', 'bert/encoder/layer_5/attention/self/query/kernel:0', 'bert/encoder/layer_5/attention/self/query/bias:0', 'bert/encoder/layer_5/attention/self/key/kernel:0', 'bert/encoder/layer_5/attention/self/key/bias:0', 'bert/encoder/layer_5/attention/self/value/kernel:0', 'bert/encoder/layer_5/attention/self/value/bias:0', 'bert/encoder/layer_5/attention/output/dense/kernel:0', 'bert/encoder/layer_5/attention/output/dense/bias:0', 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_5/intermediate/kernel:0', 'bert/encoder/layer_5/intermediate/bias:0', 'bert/encoder/layer_5/output/dense/kernel:0', 'bert/encoder/layer_5/output/dense/bias:0', 'bert/encoder/layer_5/output/LayerNorm/gamma:0', 'bert/encoder/layer_5/output/LayerNorm/beta:0', 'bert/encoder/layer_6/attention/self/query/kernel:0', 'bert/encoder/layer_6/attention/self/query/bias:0', 'bert/encoder/layer_6/attention/self/key/kernel:0', 'bert/encoder/layer_6/attention/self/key/bias:0', 'bert/encoder/layer_6/attention/self/value/kernel:0', 'bert/encoder/layer_6/attention/self/value/bias:0', 'bert/encoder/layer_6/attention/output/dense/kernel:0', 'bert/encoder/layer_6/attention/output/dense/bias:0', 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_6/intermediate/kernel:0', 'bert/encoder/layer_6/intermediate/bias:0', 'bert/encoder/layer_6/output/dense/kernel:0', 'bert/encoder/layer_6/output/dense/bias:0', 'bert/encoder/layer_6/output/LayerNorm/gamma:0', 'bert/encoder/layer_6/output/LayerNorm/beta:0', 'bert/encoder/layer_7/attention/self/query/kernel:0', 'bert/encoder/layer_7/attention/self/query/bias:0', 'bert/encoder/layer_7/attention/self/key/kernel:0', 'bert/encoder/layer_7/attention/self/key/bias:0', 'bert/encoder/layer_7/attention/self/value/kernel:0', 'bert/encoder/layer_7/attention/self/value/bias:0', 'bert/encoder/layer_7/attention/output/dense/kernel:0', 'bert/encoder/layer_7/attention/output/dense/bias:0', 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_7/intermediate/kernel:0', 'bert/encoder/layer_7/intermediate/bias:0', 'bert/encoder/layer_7/output/dense/kernel:0', 'bert/encoder/layer_7/output/dense/bias:0', 'bert/encoder/layer_7/output/LayerNorm/gamma:0', 'bert/encoder/layer_7/output/LayerNorm/beta:0'].\n"
     ]
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
